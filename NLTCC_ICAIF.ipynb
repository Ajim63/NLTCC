{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "342c0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#import networkx as nx\n",
    "import copy\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras as k\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "import Utilities as util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20216600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46791003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a41e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_firm: 293 \n",
      "no_quarter: 32 \n",
      "no_analyst: 488\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "\n",
    "return_data = pd.read_csv('Data/return_data')\n",
    "\n",
    "Firm_CR = pd.read_csv('Data/Firm_CR.csv')\n",
    "Firm_CR.set_index(['yq', 'firmID'], inplace =True)\n",
    "EPS_S = pd.read_csv('Data/EPS_S.csv')\n",
    "EPS_S.set_index(['yq', 'firmID'], inplace =True)\n",
    "\n",
    "Y_All= pd.read_csv('Data/Y_All.csv')\n",
    "Y_All.set_index(['yq', 'firmID'], inplace =True)\n",
    "\n",
    "no_firm = len(EPS_S.groupby('firmID').size())\n",
    "no_quarter = len(EPS_S.groupby('yq').size())\n",
    "no_analyst = EPS_S.shape[1]\n",
    "print(\"no_firm:\", no_firm, '\\n'\n",
    "      \"no_quarter:\", no_quarter,'\\n' \n",
    "      \"no_analyst:\", no_analyst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6579f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Correlation Matrix and to be used for return similarity regularization\n",
    "return_cor = return_data[['date', 'firmID', 'ret']]\n",
    "return_cor = return_cor.set_index(['date', 'firmID']).unstack()\n",
    "return_cor.columns = return_cor.columns.droplevel()\n",
    "\n",
    "D_firm = util.Get_D(return_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db11a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c73914b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3afb2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set hyper-parameters\n",
    "\n",
    "lr = 1e-4\n",
    "rank = 10\n",
    "nc = rank\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "seed = 3\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a340ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda_1 = 0.01\n",
    "lamda_2 = 0.01\n",
    "lamda  = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajim/miniconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/ajim/miniconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/ajim/miniconda3/lib/python3.9/site-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajim/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5514/5514 [==============================] - 49s 9ms/step - loss: 0.9972 - mse: 0.9972 - mae: 0.6385 - mape_keras: 92.6642 - val_loss: 0.9806 - val_mse: 0.9806 - val_mae: 0.6309 - val_mape_keras: 95.4324\n",
      "Epoch 2/5\n",
      "5514/5514 [==============================] - 48s 9ms/step - loss: 0.9613 - mse: 0.9613 - mae: 0.6199 - mape_keras: 94.1729 - val_loss: 0.9366 - val_mse: 0.9366 - val_mae: 0.6153 - val_mape_keras: 98.1749\n",
      "Epoch 3/5\n",
      " 862/5514 [===>..........................] - ETA: 38s - loss: 0.9072 - mse: 0.9072 - mae: 0.6074 - mape_keras: 95.2436"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "All_Train_predicted= {}\n",
    "All_Test_predicted = {}\n",
    "\n",
    "\n",
    "#for i in range(201602,201603):\n",
    "#for i in (201501, 201502, 201503, 201504, 201601, 201602, 201603, 201604):\n",
    "for i in (201603, 201604): \n",
    "    print(i)\n",
    "    \n",
    "    F_C = Firm_CR.iloc[Firm_CR.index.get_level_values('yq') <= i]\n",
    "    N_Q = len(F_C.groupby('yq').size())\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    #F_power = pt.fit_transform(F_C)\n",
    "    F_power = scaler.fit_transform(F_C.values)\n",
    "    #F_power = pd.DataFrame(F_power, index=F_C.index, columns=F_C.columns)\n",
    "    M_data = pd.DataFrame(F_power, index=F_C.index, columns=F_C.columns)\n",
    "    \n",
    "   \n",
    "        \n",
    "    Y_train = Y_All.iloc[Y_All.index.get_level_values('yq') < i].values.flatten()\n",
    "    Y_test = Y_All.iloc[Y_All.index.get_level_values('yq') == i].values.flatten()\n",
    "    \n",
    "    W_original = util.create_W_matrix(M_data)\n",
    "    \n",
    "    X_tensor = M_data.values.reshape(N_Q, -1, M_data.shape[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # creating data file and indices\n",
    "    shape = np.array(X_tensor.shape)\n",
    "\n",
    "    #getting true values and indices\n",
    "    tr_vals = X_tensor[~np.isnan(X_tensor)]\n",
    "    tr_idxs = np.argwhere(np.isnan(X_tensor) ==0)\n",
    "    \n",
    "       \n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "    #set_session(device_count={\"GPU\": 0}, seed=seed)\n",
    "    optim = k.optimizers.Adam(lr=lr)\n",
    "\n",
    "    model = util.create_NLTC(shape, rank, nc)\n",
    "    #model.compile(optim, loss=[\"mse\"], metrics=[\"mae\", mape_keras])\n",
    "    model.compile(optim, loss=util.regularized_loss_1(model.weights[1], D_firm, lamda), metrics=[\"mse\", \"mae\", util.mape_keras])\n",
    "    #model.compile(optim, loss=util.regularized_loss(model.weights[0], model.weights[1], D_firm, lamda_1, lamda_2), metrics=[\"mse\", \"mae\", util.mape_keras]) \n",
    "    \n",
    "    hists = model.fit(\n",
    "    x=util.transform(tr_idxs),\n",
    "    y=tr_vals,\n",
    "    verbose=verbose,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[k.callbacks.EarlyStopping(\n",
    "        #monitor=\"val_mean_absolute_error\", \n",
    "        monitor=\"val_mae\",\n",
    "        patience=20, \n",
    "        restore_best_weights=True)], );\n",
    "    \n",
    "    \n",
    "    all_indices = np.argwhere(np.random.rand(X_tensor.shape[0], X_tensor.shape[1], X_tensor.shape[2]))\n",
    "    all_imputed = model.predict(transform(all_indices), batch_size= 64, verbose=1)\n",
    "\n",
    "    imp_mat_costco = all_imputed.reshape(M_data.shape[0], M_data.shape[1])\n",
    "    \n",
    "    X_imputed = (imp_mat_costco * (1-W_original)) + np.nan_to_num(M_data.values)\n",
    "    X_imputed_df = pd.DataFrame(X_imputed, index =M_data.index, columns = M_data.columns )\n",
    "\n",
    "    Imputed_matrices[i] = X_imputed_df\n",
    "    \n",
    "    X_imputed_df = X_imputed_df[list(data_all.columns)]\n",
    "    \n",
    "    X_train  =   X_imputed_df.iloc[X_imputed_df.index.get_level_values('yq') < i].values\n",
    "    X_test=   X_imputed_df.iloc[X_imputed_df.index.get_level_values('yq') == i].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('********* Model SVR ***********')\n",
    "    clf = SVR(gamma='scale',  C=10, epsilon=0.00001)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    y_tr_pred = clf.predict(X_train)\n",
    "    y_ts_pred = clf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    SVRtrain_result[i] = util.Get_performance(Y_train, y_tr_pred)\n",
    "    SVRtest_result[i] = util.Get_performance(Y_test, y_ts_pred)\n",
    "    \n",
    "    \n",
    "\n",
    "    print('********* Model XGBOOST ***********')\n",
    "    model_xgb = XGBRegressor(silent=False, \n",
    "                      learning_rate=0.1,  \n",
    "                      n_estimators=1000, \n",
    "                      reg_alpha = 0.001,\n",
    "                      max_depth=5, \n",
    "                      gamma=.1)\n",
    "    model_xgb.fit(X_train, Y_train)\n",
    "    y_tr_pred = model_xgb.predict(X_train)\n",
    "    y_ts_pred = model_xgb.predict(X_test)\n",
    "    \n",
    "    \n",
    "    All_Train_predicted[i] = y_tr_pred\n",
    "    All_Test_predicted[i] = y_ts_pred \n",
    "    \n",
    "    XGBtrain_result[i] = util.Get_performance(Y_train, y_tr_pred)\n",
    "    XGBtest_result[i] = util.Get_performance(Y_test, y_ts_pred)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4cd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13021343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
